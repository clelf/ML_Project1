{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Additionally added libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "#### Remember to unpack data from .zip folders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigating loaded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 138.47 ,   51.655,   97.827, ...,    1.24 ,   -2.475,  113.497],\n",
       "       [ 160.937,   68.768,  103.235, ..., -999.   , -999.   ,   46.226],\n",
       "       [-999.   ,  162.172,  125.953, ..., -999.   , -999.   ,   44.251],\n",
       "       ...,\n",
       "       [ 105.457,   60.526,   75.839, ..., -999.   , -999.   ,   41.992],\n",
       "       [  94.951,   19.362,   68.812, ..., -999.   , -999.   ,    0.   ],\n",
       "       [-999.   ,   72.756,   70.831, ..., -999.   , -999.   ,    0.   ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 1. 1. 0. 0. 3. 2. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "tX.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 1. 1. 0. 0. 3. 2. 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Setting -999 to NaN values\n",
    "tX[tX==-999] = np.nan\n",
    "tX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical exploratory data analysis\n",
    "# row1: mean | row2: variance | row3: standard deviation | row4: minimum value | row5: maximum value | row6: number of NaN's\n",
    "feature_details = np.zeros([7, tX.shape[1]])\n",
    "for i in range(tX.shape[1]):\n",
    "    feature_details[0, i] = np.nanmean(tX[:,i])\n",
    "    feature_details[1, i] = np.nanvar(tX[:,i])\n",
    "    feature_details[2, i] = np.nanstd(tX[:,i])\n",
    "    feature_details[3, i] = np.nanmin(tX[:,i])\n",
    "    feature_details[4, i] = np.nanmax(tX[:,i])\n",
    "    feature_details[5, i] = np.isnan(tX[:,i]).sum()\n",
    "    feature_details[6, i] = np.nanmedian(tX[:,i])\n",
    "#.... I dont know how to represent this in a nice way without pandas.DataFrame, without doing a lot of coding...\n",
    "#print(feature_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Statistics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mean</th>\n",
       "      <td>121.858528</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>2.403735</td>\n",
       "      <td>371.783360</td>\n",
       "      <td>-0.821688</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>158.432217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>84.822105</td>\n",
       "      <td>-0.003275</td>\n",
       "      <td>-0.012393</td>\n",
       "      <td>57.679474</td>\n",
       "      <td>-0.011845</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variance</th>\n",
       "      <td>3283.063262</td>\n",
       "      <td>1249.255942</td>\n",
       "      <td>1666.975303</td>\n",
       "      <td>4052.029594</td>\n",
       "      <td>3.035311</td>\n",
       "      <td>158162.573194</td>\n",
       "      <td>12.847474</td>\n",
       "      <td>0.612947</td>\n",
       "      <td>496.106539</td>\n",
       "      <td>13387.851528</td>\n",
       "      <td>...</td>\n",
       "      <td>3.284138</td>\n",
       "      <td>16002.060938</td>\n",
       "      <td>0.955358</td>\n",
       "      <td>3679.887218</td>\n",
       "      <td>3.184583</td>\n",
       "      <td>3.288345</td>\n",
       "      <td>1023.076126</td>\n",
       "      <td>4.127921</td>\n",
       "      <td>3.301261</td>\n",
       "      <td>9607.031571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Std</th>\n",
       "      <td>57.298021</td>\n",
       "      <td>35.344815</td>\n",
       "      <td>40.828609</td>\n",
       "      <td>63.655554</td>\n",
       "      <td>1.742214</td>\n",
       "      <td>397.696584</td>\n",
       "      <td>3.584337</td>\n",
       "      <td>0.782910</td>\n",
       "      <td>22.273449</td>\n",
       "      <td>115.705884</td>\n",
       "      <td>...</td>\n",
       "      <td>1.812219</td>\n",
       "      <td>126.499253</td>\n",
       "      <td>0.977424</td>\n",
       "      <td>60.662074</td>\n",
       "      <td>1.784540</td>\n",
       "      <td>1.813379</td>\n",
       "      <td>31.985561</td>\n",
       "      <td>2.031729</td>\n",
       "      <td>1.816937</td>\n",
       "      <td>98.015466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>9.044000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.602000</td>\n",
       "      <td>-18.066000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>46.104000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.499000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>-4.500000</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>1852.462000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n-NaNs</th>\n",
       "      <td>38114.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>177457.000000</td>\n",
       "      <td>177457.000000</td>\n",
       "      <td>177457.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99913.000000</td>\n",
       "      <td>99913.000000</td>\n",
       "      <td>99913.000000</td>\n",
       "      <td>177457.000000</td>\n",
       "      <td>177457.000000</td>\n",
       "      <td>177457.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>112.406000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>2.107000</td>\n",
       "      <td>225.885000</td>\n",
       "      <td>-0.244000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>120.664500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.561000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>47.902000</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>-0.002000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0            1            2            3   \\\n",
       "Statistics                                                        \n",
       "Mean          121.858528    49.239819    81.181982    57.895962   \n",
       "Variance     3283.063262  1249.255942  1666.975303  4052.029594   \n",
       "Std            57.298021    35.344815    40.828609    63.655554   \n",
       "min             9.044000     0.000000     6.329000     0.000000   \n",
       "max          1192.026000   690.075000  1349.351000  2834.999000   \n",
       "n-NaNs      38114.000000     0.000000     0.000000     0.000000   \n",
       "median        112.406000    46.524000    73.752000    38.467500   \n",
       "\n",
       "                       4              5              6         7   \\\n",
       "Statistics                                                          \n",
       "Mean             2.403735     371.783360      -0.821688  2.373100   \n",
       "Variance         3.035311  158162.573194      12.847474  0.612947   \n",
       "Std              1.742214     397.696584       3.584337  0.782910   \n",
       "min              0.000000      13.602000     -18.066000  0.208000   \n",
       "max              8.503000    4974.979000      16.690000  5.684000   \n",
       "n-NaNs      177457.000000  177457.000000  177457.000000  0.000000   \n",
       "median           2.107000     225.885000      -0.244000  2.491500   \n",
       "\n",
       "                     8             9   ...        20            21        22  \\\n",
       "Statistics                             ...                                     \n",
       "Mean          18.917332    158.432217  ... -0.010119    209.797178  0.979176   \n",
       "Variance     496.106539  13387.851528  ...  3.284138  16002.060938  0.955358   \n",
       "Std           22.273449    115.705884  ...  1.812219    126.499253  0.977424   \n",
       "min            0.000000     46.104000  ... -3.142000     13.678000  0.000000   \n",
       "max         2834.999000   1852.462000  ...  3.142000   2003.976000  3.000000   \n",
       "n-NaNs         0.000000      0.000000  ...  0.000000      0.000000  0.000000   \n",
       "median        12.315500    120.664500  ... -0.024000    179.739000  1.000000   \n",
       "\n",
       "                      23            24            25             26  \\\n",
       "Statistics                                                            \n",
       "Mean           84.822105     -0.003275     -0.012393      57.679474   \n",
       "Variance     3679.887218      3.184583      3.288345    1023.076126   \n",
       "Std            60.662074      1.784540      1.813379      31.985561   \n",
       "min            30.000000     -4.499000     -3.142000      30.000000   \n",
       "max          1120.573000      4.499000      3.141000     721.456000   \n",
       "n-NaNs      99913.000000  99913.000000  99913.000000  177457.000000   \n",
       "median         65.561000      0.000000     -0.033000      47.902000   \n",
       "\n",
       "                       27             28           29  \n",
       "Statistics                                             \n",
       "Mean            -0.011845      -0.001582    73.064591  \n",
       "Variance         4.127921       3.301261  9607.031571  \n",
       "Std              2.031729       1.816937    98.015466  \n",
       "min             -4.500000      -3.142000     0.000000  \n",
       "max              4.500000       3.142000  1633.433000  \n",
       "n-NaNs      177457.000000  177457.000000     0.000000  \n",
       "median          -0.010000      -0.002000    40.512500  \n",
       "\n",
       "[7 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing pandas just to make this numerical EDA nicer to view. \n",
    "# IMPORTANT!!! DO NOT USE IN PROJECT SUBMISSION\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(feature_details)\n",
    "df.index = ['Mean', 'Variance', 'Std', 'min', 'max', 'n-NaNs', 'median']\n",
    "df.index.name = 'Statistics'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to standardize dataset - a wide variety of ranges can be observed in the dataset. Would lead to a biased learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store mean and variance\n",
    "feature_mean = feature_details[0, :]\n",
    "feature_std = feature_details[2, :]\n",
    "feature_median = feature_details[6, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cleaning nans\n",
    "from clean_nan import *\n",
    "\n",
    "tx_ = clean_nan(tX, feature_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.89913530e-01  6.83319669e-02  4.07680272e-01 ...  6.16147878e-01\n",
      "  -1.36131161e+00  4.12510497e-01]\n",
      " [ 6.82021310e-01  5.52504823e-01  5.40136414e-01 ...  9.08223761e-04\n",
      "  -2.29898355e-04 -2.73819964e-01]\n",
      " [-1.64971287e-01  3.19515553e+00  1.09655998e+00 ...  9.08223761e-04\n",
      "  -2.29898355e-04 -2.93969845e-01]\n",
      " ...\n",
      " [-2.86249472e-01  3.19316447e-01 -1.30863670e-01 ...  9.08223761e-04\n",
      "  -2.29898355e-04 -3.17017229e-01]\n",
      " [-4.69606588e-01 -8.45323970e-01 -3.02973380e-01 ...  9.08223761e-04\n",
      "  -2.29898355e-04 -7.45439413e-01]\n",
      " [-1.64971287e-01  6.65336083e-01 -2.53522760e-01 ...  9.08223761e-04\n",
      "  -2.29898355e-04 -7.45439413e-01]]\n"
     ]
    }
   ],
   "source": [
    "# create standardized dataset\n",
    "#should be put into a method\n",
    "for i in range(tx_.shape[1]):\n",
    "    if (i!=22):\n",
    "        tx_[:,i] = (tx_[:,i] - feature_mean[i])/feature_std[i]\n",
    "\n",
    "print(tx_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 1., 0., 0., 3., 2., 1., 0., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tx_[0:10,22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Double checking array\n",
    "tx_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.289914</td>\n",
       "      <td>0.068332</td>\n",
       "      <td>0.407680</td>\n",
       "      <td>-0.469966</td>\n",
       "      <td>-0.857377</td>\n",
       "      <td>-0.621258</td>\n",
       "      <td>0.973036</td>\n",
       "      <td>0.882478</td>\n",
       "      <td>1.033099</td>\n",
       "      <td>0.339894</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147267</td>\n",
       "      <td>0.386847</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.286622</td>\n",
       "      <td>1.206627</td>\n",
       "      <td>0.251681</td>\n",
       "      <td>-0.363210</td>\n",
       "      <td>0.616148</td>\n",
       "      <td>-1.361312</td>\n",
       "      <td>0.412510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.682021</td>\n",
       "      <td>0.552505</td>\n",
       "      <td>0.540136</td>\n",
       "      <td>-0.153167</td>\n",
       "      <td>-0.170321</td>\n",
       "      <td>-0.366858</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>1.404888</td>\n",
       "      <td>-0.756027</td>\n",
       "      <td>-0.287584</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.051683</td>\n",
       "      <td>-0.357719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.636248</td>\n",
       "      <td>0.408102</td>\n",
       "      <td>0.645421</td>\n",
       "      <td>-0.305684</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.273820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.164971</td>\n",
       "      <td>3.195156</td>\n",
       "      <td>1.096560</td>\n",
       "      <td>-0.349710</td>\n",
       "      <td>-0.170321</td>\n",
       "      <td>-0.366858</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>0.989770</td>\n",
       "      <td>-0.430168</td>\n",
       "      <td>0.340361</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.200672</td>\n",
       "      <td>0.400135</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.668805</td>\n",
       "      <td>1.152271</td>\n",
       "      <td>-1.111520</td>\n",
       "      <td>-0.305684</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.293970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.384768</td>\n",
       "      <td>0.910379</td>\n",
       "      <td>-0.005853</td>\n",
       "      <td>-0.903016</td>\n",
       "      <td>-0.170321</td>\n",
       "      <td>-0.366858</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>1.196690</td>\n",
       "      <td>-0.830735</td>\n",
       "      <td>-0.712705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038692</td>\n",
       "      <td>-0.978149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.317515</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>-0.011364</td>\n",
       "      <td>-0.305684</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.745439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.942536</td>\n",
       "      <td>-0.914556</td>\n",
       "      <td>1.313369</td>\n",
       "      <td>-0.651804</td>\n",
       "      <td>-0.170321</td>\n",
       "      <td>-0.366858</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>1.938794</td>\n",
       "      <td>-0.112795</td>\n",
       "      <td>-0.868143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.475042</td>\n",
       "      <td>-1.238475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.317515</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>-0.011364</td>\n",
       "      <td>-0.305684</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.745439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249995</th>\n",
       "      <td>-0.164971</td>\n",
       "      <td>0.643636</td>\n",
       "      <td>-1.093204</td>\n",
       "      <td>-0.830312</td>\n",
       "      <td>-0.170321</td>\n",
       "      <td>-0.366858</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>-1.253146</td>\n",
       "      <td>-0.622954</td>\n",
       "      <td>-0.886214</td>\n",
       "      <td>...</td>\n",
       "      <td>1.583208</td>\n",
       "      <td>-0.514882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.317515</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>-0.011364</td>\n",
       "      <td>-0.305684</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.745439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249996</th>\n",
       "      <td>-0.164971</td>\n",
       "      <td>0.252913</td>\n",
       "      <td>-0.320829</td>\n",
       "      <td>-0.557013</td>\n",
       "      <td>-0.170321</td>\n",
       "      <td>-0.366858</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>0.270657</td>\n",
       "      <td>0.158111</td>\n",
       "      <td>-0.931795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.472835</td>\n",
       "      <td>-1.022845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.317515</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>-0.011364</td>\n",
       "      <td>-0.305684</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.745439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249997</th>\n",
       "      <td>-0.286249</td>\n",
       "      <td>0.319316</td>\n",
       "      <td>-0.130864</td>\n",
       "      <td>-0.284955</td>\n",
       "      <td>-0.170321</td>\n",
       "      <td>-0.366858</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>0.021586</td>\n",
       "      <td>0.146617</td>\n",
       "      <td>-0.328162</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.589146</td>\n",
       "      <td>-0.086089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.706044</td>\n",
       "      <td>1.010498</td>\n",
       "      <td>-0.084708</td>\n",
       "      <td>-0.305684</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.317017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249998</th>\n",
       "      <td>-0.469607</td>\n",
       "      <td>-0.845324</td>\n",
       "      <td>-0.302973</td>\n",
       "      <td>-0.697378</td>\n",
       "      <td>-0.170321</td>\n",
       "      <td>-0.366858</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>1.266941</td>\n",
       "      <td>-0.243040</td>\n",
       "      <td>-0.886500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453102</td>\n",
       "      <td>-0.767429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.317515</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>-0.011364</td>\n",
       "      <td>-0.305684</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.745439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249999</th>\n",
       "      <td>-0.164971</td>\n",
       "      <td>0.665336</td>\n",
       "      <td>-0.253523</td>\n",
       "      <td>-0.792028</td>\n",
       "      <td>-0.170321</td>\n",
       "      <td>-0.366858</td>\n",
       "      <td>0.161170</td>\n",
       "      <td>-0.444623</td>\n",
       "      <td>-0.513541</td>\n",
       "      <td>-0.649856</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.875104</td>\n",
       "      <td>-0.872671</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.317515</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>-0.011364</td>\n",
       "      <td>-0.305684</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>-0.000230</td>\n",
       "      <td>-0.745439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250000 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \\\n",
       "0       0.289914  0.068332  0.407680 -0.469966 -0.857377 -0.621258  0.973036   \n",
       "1       0.682021  0.552505  0.540136 -0.153167 -0.170321 -0.366858  0.161170   \n",
       "2      -0.164971  3.195156  1.096560 -0.349710 -0.170321 -0.366858  0.161170   \n",
       "3       0.384768  0.910379 -0.005853 -0.903016 -0.170321 -0.366858  0.161170   \n",
       "4       0.942536 -0.914556  1.313369 -0.651804 -0.170321 -0.366858  0.161170   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "249995 -0.164971  0.643636 -1.093204 -0.830312 -0.170321 -0.366858  0.161170   \n",
       "249996 -0.164971  0.252913 -0.320829 -0.557013 -0.170321 -0.366858  0.161170   \n",
       "249997 -0.286249  0.319316 -0.130864 -0.284955 -0.170321 -0.366858  0.161170   \n",
       "249998 -0.469607 -0.845324 -0.302973 -0.697378 -0.170321 -0.366858  0.161170   \n",
       "249999 -0.164971  0.665336 -0.253523 -0.792028 -0.170321 -0.366858  0.161170   \n",
       "\n",
       "              7         8         9   ...        20        21   22        23  \\\n",
       "0       0.882478  1.033099  0.339894  ... -0.147267  0.386847  2.0 -0.286622   \n",
       "1       1.404888 -0.756027 -0.287584  ... -1.051683 -0.357719  1.0 -0.636248   \n",
       "2       0.989770 -0.430168  0.340361  ... -1.200672  0.400135  1.0 -0.668805   \n",
       "3       1.196690 -0.830735 -0.712705  ...  0.038692 -0.978149  0.0 -0.317515   \n",
       "4       1.938794 -0.112795 -0.868143  ... -0.475042 -1.238475  0.0 -0.317515   \n",
       "...          ...       ...       ...  ...       ...       ...  ...       ...   \n",
       "249995 -1.253146 -0.622954 -0.886214  ...  1.583208 -0.514882  0.0 -0.317515   \n",
       "249996  0.270657  0.158111 -0.931795  ... -0.472835 -1.022845  0.0 -0.317515   \n",
       "249997  0.021586  0.146617 -0.328162  ... -1.589146 -0.086089  1.0 -0.706044   \n",
       "249998  1.266941 -0.243040 -0.886500  ...  0.453102 -0.767429  0.0 -0.317515   \n",
       "249999 -0.444623 -0.513541 -0.649856  ... -0.875104 -0.872671  0.0 -0.317515   \n",
       "\n",
       "              24        25        26        27        28        29  \n",
       "0       1.206627  0.251681 -0.363210  0.616148 -1.361312  0.412510  \n",
       "1       0.408102  0.645421 -0.305684  0.000908 -0.000230 -0.273820  \n",
       "2       1.152271 -1.111520 -0.305684  0.000908 -0.000230 -0.293970  \n",
       "3       0.001835 -0.011364 -0.305684  0.000908 -0.000230 -0.745439  \n",
       "4       0.001835 -0.011364 -0.305684  0.000908 -0.000230 -0.745439  \n",
       "...          ...       ...       ...       ...       ...       ...  \n",
       "249995  0.001835 -0.011364 -0.305684  0.000908 -0.000230 -0.745439  \n",
       "249996  0.001835 -0.011364 -0.305684  0.000908 -0.000230 -0.745439  \n",
       "249997  1.010498 -0.084708 -0.305684  0.000908 -0.000230 -0.317017  \n",
       "249998  0.001835 -0.011364 -0.305684  0.000908 -0.000230 -0.745439  \n",
       "249999  0.001835 -0.011364 -0.305684  0.000908 -0.000230 -0.745439  \n",
       "\n",
       "[250000 rows x 30 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Test = pd.DataFrame(tx_) \n",
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving arrays to .py file. Can easily be loaded with np.load('path' + 'filename')\n",
    "####np.save('tX_cleaned', tX)\n",
    "####np.save('tX_standardized', tX_standardized)\n",
    "# Commented this section out to prevent overwriting of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from build_polynomial import*\n",
    "tx_ = build_poly(tx_, degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression using gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from least_squares_GD import *\n",
    "from costs import compute_mse\n",
    "from least_squares_GD import *\n",
    "from parameter_tuning import gamma_tuning_SGD\n",
    "from parameter_tuning import gamma_tuning_GD\n",
    "\n",
    "# Initialization of the weights\n",
    "initial_w = np.zeros(tx_.shape[1])\n",
    "# Define the parameters necessary for gradient descent: need to tune gamma. \n",
    "# we use the gamma_tuning_SGD for less costly tuning\n",
    "max_iters = 50\n",
    "gamma = gamma_tuning_GD(y, tx_, initial_w, max_iters)\n",
    "\n",
    "w1, loss1 = least_squares_GD(y, tx_, initial_w, max_iters, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.56421763e-04  1.61064854e-05 -1.66509013e-04 -5.95784163e-06\n",
      "  9.17488001e-05  7.13970251e-05  9.76098102e-05 -6.52239914e-05\n",
      "  5.88701787e-06 -6.79307110e-06  7.32371563e-05 -9.23839491e-05\n",
      "  1.28989331e-04  4.59095883e-05  1.11902521e-04 -4.43027894e-07\n",
      " -2.08955241e-06 -1.45673955e-05  7.26680141e-07  1.95210360e-06\n",
      "  1.10745695e-05  3.54773351e-06  6.47505656e-05 -9.09667804e-05\n",
      "  6.34418075e-05 -8.54267396e-08  1.04747183e-06  4.01699090e-05\n",
      "  4.67764367e-08 -8.75563081e-07  6.41473778e-05 -3.43273837e-04\n",
      " -1.67167634e-04 -3.98190226e-04 -4.39932273e-06  2.67167610e-05\n",
      "  5.54781528e-05  3.15983994e-05 -2.32935639e-04 -8.91964491e-05\n",
      " -1.19306228e-04 -1.68983872e-04 -1.18613587e-04 -7.28247491e-06\n",
      " -3.19504424e-05 -2.14063589e-04 -1.57096074e-04 -1.60774879e-04\n",
      " -2.27558879e-04 -1.57693530e-04  8.73117469e-06 -1.56585610e-04\n",
      " -1.46582835e-04 -1.89653725e-04 -4.10290982e-05 -2.96541303e-08\n",
      " -5.78263039e-05 -5.94804625e-05  1.87942388e-05 -1.50877087e-05\n",
      " -1.38330574e-04]\n",
      "0.9983114818290529\n"
     ]
    }
   ],
   "source": [
    "print(w1)\n",
    "print(loss1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least squares with SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9986094795174398\n"
     ]
    }
   ],
   "source": [
    "from least_squares_SGD import *\n",
    "#No need to re-tune gamma BUT NOT SURE\n",
    "#Here batch_size is set at 1\n",
    "\n",
    "\n",
    "# Initialization of the weights BUT we could use w1 as a start AND careful with tuning\n",
    "initial_w = np.zeros(tx_.shape[1])\n",
    "gamma = gamma_tuning_GD(y, tx_, initial_w, max_iters)\n",
    "\n",
    "w2, loss2 = least_squares_SGD(y, tx_, initial_w, 1, max_iters, gamma)\n",
    "#print(w2)\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Least Squares using Normal Equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7942644907345137\n"
     ]
    }
   ],
   "source": [
    "from least_squares import *\n",
    "from build_polynomial import *\n",
    "from parameter_tuning import degree_tuning_LS\n",
    "\n",
    "# degree = degree_tuning_LS(y , tx_)\n",
    "# Initialization of the weights BUT could use w2\n",
    "initial_w = np.zeros(tx_.shape[1]) \n",
    "\n",
    "w3, loss3 = least_squares(y, tx_)\n",
    "#_, loss3_expand = least_squares(y, poly_x)\n",
    "print(loss3)\n",
    "#print(loss3_expand)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.63111831e-01  1.47266876e-01 -2.43829448e-01 -3.08236396e-01\n",
      "  1.40559507e-01 -1.04769211e-01 -2.14882454e-02 -1.21353005e-01\n",
      "  2.60084229e-01 -9.85768352e-03 -2.34804069e+02 -1.89024149e-01\n",
      "  4.07272541e-02  1.28947317e-01  4.56793045e+01 -5.92619823e-04\n",
      "  1.46679685e-04  4.50106722e+01  7.85046580e-04  1.89339154e-03\n",
      "  7.42601090e-03  6.24533643e-04 -3.25812640e-02 -2.29069142e-02\n",
      "  1.04650722e-01 -1.66705812e-04  9.85384053e-04  5.46322454e-02\n",
      "  1.25020335e-03 -2.30359596e-03  1.98828722e+02 -2.23868264e-02\n",
      "  3.62792138e-02  1.69459325e-02  3.31057858e-03  6.48220893e-02\n",
      " -1.35246520e-03 -2.69044573e-02 -5.96121517e-02  7.54987826e-04\n",
      " -7.00676127e-03  1.82416826e-02  5.61851664e-02  7.55385377e-02\n",
      " -1.42062796e-02 -3.37266499e-02 -1.90636841e-03 -1.97768807e-02\n",
      " -5.65040568e-02 -4.92036762e-04 -3.23446521e-03 -8.15830315e-04\n",
      " -2.18581124e-02 -2.84789367e-02 -1.72903131e-02  1.27378547e-01\n",
      "  1.79342518e-04 -1.01928592e-03  1.44181245e-01 -1.57972934e-04\n",
      "  1.71507065e-02]\n",
      "0.7942644907345134\n"
     ]
    }
   ],
   "source": [
    "from ridge_regression import *\n",
    "from parameter_tuning import lambda_tuning_ridge\n",
    "\n",
    "# Tuning of lambda\n",
    "lambda_ = lambda_tuning_ridge(y, tx_)\n",
    "\n",
    "# Computing the loss\n",
    "w4, loss4 = ridge_regression(y, tx_, lambda_)\n",
    "#print(w4)\n",
    "print(loss4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cleme\\Documents\\GitHub\\ML_Project1\\scripts\\logistic_regression.py:18: RuntimeWarning: overflow encountered in exp\n",
      "  a = np.exp(-value)\n",
      "C:\\Users\\cleme\\Documents\\GitHub\\ML_Project1\\scripts\\logistic_regression.py:14: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = - (1 / tx.shape[0]) * np.sum((y * np.log(a)) + ((1 - y) * np.log(1 - a)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10290153506270981\n",
      "0.001\n"
     ]
    }
   ],
   "source": [
    "from logistic_regression import *\n",
    "from parameter_tuning import param_tuning_log\n",
    "\n",
    "# Initialization of the weights BUT could use w2\n",
    "initial_w = np.zeros(tx_.shape[1])\n",
    "\n",
    "# Tuning of gamma\n",
    "lambda_=0.0\n",
    "max_iters=50\n",
    "gamma = param_tuning_log(y, tx_, initial_w, max_iters, lambda_)\n",
    "\n",
    "w5, loss5 = logistic_regression(y, tx_, initial_w, max_iters, gamma, lambda_)\n",
    "print(loss5)\n",
    "#print(w5)\n",
    "print(gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002154434690031882\n"
     ]
    }
   ],
   "source": [
    "from reg_logistic_regression import *\n",
    "from parameter_tuning import param_tuning_reg_log\n",
    "\n",
    "# Initialization of the weights BUT could use w2\n",
    "initial_w = np.zeros(tx_.shape[1])\n",
    "\n",
    "# Tuning of gamma\n",
    "lambda_=5\n",
    "gamma = param_tuning_reg_log(y, tx_, initial_w, max_iters, lambda_)\n",
    "#gamma=0.00000001\n",
    "w6, loss6 = reg_logistic_regression(y, tx_, lambda_, initial_w, max_iters, gamma)\n",
    "#print(loss6)\n",
    "#print(w6)\n",
    "print(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20519960108320173\n"
     ]
    }
   ],
   "source": [
    "print(loss6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv' # TODO: download train data and supply path here \n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STANDARDIZE TX TEST\n",
    "test_mean = np.zeros(tX_test.shape[1]).T\n",
    "test_std = np.zeros(tX_test.shape[1]).T\n",
    "for i in range(tX_test.shape[1]):\n",
    "    test_mean[i] = np.nanmean(tX_test[:,i])\n",
    "    test_std[i] = np.nanstd(tX_test[:,i])\n",
    "for i in range(tX_test.shape[1]):\n",
    "    if (i!=22):\n",
    "        tX_test[:,i] = (tX_test[:,i] - test_mean[i])/test_std[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/sample-submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(w3, tX_test) # CAREFUL IT'S W3\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../data/sample-submission.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
